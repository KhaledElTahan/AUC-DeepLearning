{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment1_part1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HNdarz1uIIZ"
      },
      "source": [
        "<table align=\"center\">\r\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/AU-DeepLearning-2020/Assignment6/blob/master/RL.ipynb\">\r\n",
        "        <img src=\"http://introtodeeplearning.com/images/colab/colab.png?v2.0\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\r\n",
        "</table>\r\n",
        "\r\n",
        "# Copyright Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSA7aTOivRhA"
      },
      "source": [
        "**Parts of this lab are based on Kaggle kernels.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfATj8pltlxh"
      },
      "source": [
        "# Lab 1 - Part1: Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOy1mYdKw5TE"
      },
      "source": [
        "![Linear Regression]()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsLKJ-4kwLYv"
      },
      "source": [
        "## 1.1.1 Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQxlb182u_gv"
      },
      "source": [
        "The problem we are trying to solve here is finding a new house which is suitable to our needs and the budget we assigned. The client who wants to buy the new house did her research and found some houses. She wrote the details of each house she visited including location, sale condition, sale type, house price, among others. She needs some help to know how much she is expected to pay to get a house that conforms with her specific needs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUidwfyPvcfv"
      },
      "source": [
        "Your task is to build a linear regression model that helps her to predict the house price depending on the given attributes she collected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeXilc2Nvg-g"
      },
      "source": [
        "## 1.1.2 Problem Details"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsHAbLgL1MsY"
      },
      "source": [
        "Let's dive into the code, explain it and show you the parts you need to fill!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n5JS__dwfiH"
      },
      "source": [
        "### 1.1.2.1 Import Needed packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm9MPDVSsDpu"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from scipy.stats import skew\r\n",
        "from scipy.stats.stats import pearsonr\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.regularizers import l1, l2\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EfciecZwm6L"
      },
      "source": [
        "### 1.1.2.2 Configure Notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW1TyciwsN9_"
      },
      "source": [
        "%config InlineBackend.figure_format = 'retina' #set 'png' here when working on notebook\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6PJSAiyx4HM"
      },
      "source": [
        "### 1.1.2.3 Work on the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcVsD6V1x-Ty"
      },
      "source": [
        "This dataset contains 80 features that demonstrate the state of the house and our target which is the house price.\r\n",
        "\r\n",
        "We begin by loading the train and test splits of the dataset using pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6zYNeXVvvRA"
      },
      "source": [
        "train = pd.read_csv(\"lab1_housing_train.csv\")\n",
        "test = pd.read_csv(\"lab1_housing_test.csv\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyl1lDq-yVFG"
      },
      "source": [
        "You can have a look at the train split of the dataset using the head command. I very much encourage you to have a deeper look on the dataset file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2JWObzgyY9t"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrXVoqAU0h1g"
      },
      "source": [
        "Data preprocessing:\r\n",
        "* First I'll transform the skewed numeric features by taking log(feature + 1) - this will make the features more normal\r\n",
        "* Create Dummy variables for the categorical features\r\n",
        "* Replace the numeric missing values (NaN's) with the mean of their respective columns\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCCi1svksOj4"
      },
      "source": [
        "# Concatenate all the data\r\n",
        "# We do this to be able to preprocess on the whole dataset\r\n",
        "all_data = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'],\r\n",
        "                      test.loc[:,'MSSubClass':'SaleCondition']))\r\n",
        "\r\n",
        "# Log transform the target y in training data - by reference inside all\r\n",
        "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\r\n",
        "\r\n",
        "# Log transform skewed numeric features:\r\n",
        "\r\n",
        "# Get Numerical Fields\r\n",
        "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index \r\n",
        "\r\n",
        "skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewnessc\r\n",
        "skewed_feats = skewed_feats[skewed_feats > 0.75] # Get Skewed Columns\r\n",
        "skewed_feats = skewed_feats.index # Get Skewed Columns indices\r\n",
        "\r\n",
        "# Log scale skewed columns\r\n",
        "# Normalize the skewed distribution for better regression\r\n",
        "all_data[skewed_feats] = np.log1p(all_data[skewed_feats])\r\n",
        "\r\n",
        "# Create Dummy variables for the categorical features \r\n",
        "all_data = pd.get_dummies(all_data) \r\n",
        "\r\n",
        "# Replace the numeric missing values (NaN's) with the mean of their respective columns\r\n",
        "all_data = all_data.fillna(all_data.mean())\r\n",
        "\r\n",
        "# Split the data to training & testing\r\n",
        "X_train = all_data[:train.shape[0]]\r\n",
        "X_test = all_data[train.shape[0]:]\r\n",
        "y = train.SalePrice\r\n",
        "\r\n",
        "# Standardize features by removing the mean and scaling to unit variance\r\n",
        "# z = (x - u) / s\r\n",
        "X_train = StandardScaler().fit_transform(X_train)\r\n",
        "\r\n",
        "#split training data into training & validation, default splitting is 25% validation\r\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y, random_state = 3)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVa9K1Ga1vlo"
      },
      "source": [
        "### 1.1.2.4 Define your model here (TODO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IocosMrh2W3X"
      },
      "source": [
        "One important note you need to be aware of, linear regression is a neural network with only one perceptron (i.e. dense layer with one node) with a linear activation (i.e. no activation function). \n",
        "\n",
        "![One Perceptron Neural Network]()\n",
        "\n",
        "Use this note to define a **sequential model of one dense layer with one unit using Tensorflow.Keras**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh1NvkNXsVVG"
      },
      "source": [
        "# TODO: Define the Model using Tensorflow.Keras\r\n",
        "model = Sequential([\r\n",
        "    Dense(1, input_shape=(X_tr.shape[1],), activation='linear', kernel_regularizer=l2(0.05))\r\n",
        "])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSa178n-2BM-"
      },
      "source": [
        "### 1.1.2.5 Compile your model and print a summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg6Yy5oDsXyK"
      },
      "source": [
        "model.compile(loss = \"mean_squared_error\", optimizer = \"Adam\")\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FgD-Kqo3fwb"
      },
      "source": [
        "### 1.1.2.6 Train your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA4pLcN73waK"
      },
      "source": [
        "Fit your model into the training data, use the validation data to be able to plot the loss decrement during the training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAkW1KTm3TGU"
      },
      "source": [
        "hist = model.fit(X_tr, y_tr, validation_data = (X_val, y_val), epochs = 500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtdUbgUd4Ifw"
      },
      "source": [
        "And this is how you can predict an output for any number of inputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaO-wCLl3Wd_",
        "outputId": "7e28535b-243b-4654-86c0-1e7fc1731483"
      },
      "source": [
        "print(model.predict(X_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[12.631396]\n",
            " [12.315755]\n",
            " [12.572445]\n",
            " ...\n",
            " [12.52041 ]\n",
            " [12.14757 ]\n",
            " [12.717263]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6VhmPDN4Sva"
      },
      "source": [
        "### 1.1.2.7 Visualize Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bDCQffM4Zh2"
      },
      "source": [
        "It's time to see how your model's progress during the training, If all is good, you will find the validation loss decreasing without neither overfitting nor underfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEZ7SdwI2e_D"
      },
      "source": [
        "# Get training and test loss histories\r\n",
        "training_loss = hist.history['loss']\r\n",
        "val_loss = hist.history['val_loss']\r\n",
        "\r\n",
        "# Create count of the number of epochs\r\n",
        "epoch_count = range(1, len(training_loss) + 1)\r\n",
        "\r\n",
        "# Visualize loss history\r\n",
        "plt.figure()\r\n",
        "plt.plot(epoch_count, training_loss, 'r--')\r\n",
        "plt.plot(epoch_count, val_loss, 'b-')\r\n",
        "plt.legend(['Training Loss', 'Val Loss'])\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gni9AWDueGU"
      },
      "source": [
        "## 1.1.3 Conclusion:\r\n",
        "\r\n",
        "That's it! Congratulations on training a linear regression model. \r\n",
        "\r\n",
        "Make sure you finish the second part of the assignment and deliver all the requirements for the submission.\r\n",
        "\r\n"
      ]
    }
  ]
}